{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstração PyCaret\n",
    "\n",
    "## Análise supervisionada com PyCaret no desafio do LABDATA da Fundação Instituto de Administração (FIA)\n",
    "\n",
    "Realizaremos uma demonstração de aprendizagem supervisionada utilizando [PyCaret](https://pycaret.org/), uma biblioteca open source criada pelo cientista de dados e consultor da PwC Moez Ali. A biblioteca foi criada para facilitar a utilização de algoritmos de machine learning, podendo ser classificada como uma ferramenta da AutoML.\n",
    "\n",
    "Para essa demonstração utilizaremos o [desafio no Kaggle](https://www.kaggle.com/c/labdata-churn-challenge-2020/data) proposto pela Fundação Instituto de Administração (FIA) para realizar a predição de quais clientes poderiam deixar uma certa companhia telefônica (churn). O colega Mário Monnerat trouxe o desafio para o treinamento de Big Data da Sufis, realizado em outubro e novembro de 2020, o que se mostrou uma ferramenta essencial para consolidar os conceitos de análise supervisionada.\n",
    "\n",
    "\n",
    "Além da PyCaret utilizaremos as bibliotecas pandas, numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de Churn\n",
    "\n",
    "A base utilizada possui informações de cada cliente de uma companhia telefônica. Nosso intuito é prever se o cliente permanecerá contratando os serviços da empresa ou se vai sair (churn). Para tal, nos é fornecida a base de treino, que possui as informações de churn e a base de testes, que não possui e será utilizada para a previsão final.\n",
    "\n",
    "Como sabemos, devemos utilizar somente a base de treino para tomar decisões com relação a qual o melhor modelo. Desse modo, devemos ter atenção e nos valer de ferramentas como validação cruzada (cross validation) e evitar o vazamento de dados do teste para o treino. O PyCaret utiliza validação cruzada sempre que possível.\n",
    "\n",
    "## Pergunta a ser respondida\n",
    "\n",
    "Conforme prega o CRISP-DM, antes de iniciarmos qualquer modelo de machine learning, devemos nos questionar sobre qual problema queremos solucionar. Nos desafios do Kaggle isso resta facilitado, tendo em vista que já temos o problema para ser solucionado, mas o mesmo não ocorre na vida real. Sugere-se seguir os passos do CRISP-DM, com bastante atenção para a primeira fase, para que o trabalho tenha um norte bem definido. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./img/crisp.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instalar o PyCaret\n",
    "!pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados de treinamento e de teste\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setar id como indice dos dataframes\n",
    "train_df.set_index('id', inplace=True)\n",
    "test_df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando os tipos\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando missing data\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotalChanges não é numerico, transformar\n",
    "train_df['TotalCharges'] = pd.to_numeric(train_df['TotalCharges'], errors='coerce')\n",
    "test_df['TotalCharges'] = pd.to_numeric(test_df['TotalCharges'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "train_df.loc[train_df['TotalCharges'].isnull(), 'TotalCharges'] = train_df.loc[train_df['TotalCharges'].isnull(), 'MonthlyCharges'] * train_df.loc[train_df['TotalCharges'].isnull(), 'tenure']\n",
    "test_df.loc[test_df['TotalCharges'].isnull(), 'TotalCharges'] = test_df.loc[test_df['TotalCharges'].isnull(), 'MonthlyCharges'] * test_df.loc[test_df['TotalCharges'].isnull(), 'tenure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering + tratamento missing data\n",
    "train_df['tenure'] = train_df['TotalCharges'] / train_df['MonthlyCharges']\n",
    "test_df['tenure'] = test_df['TotalCharges'] /  test_df['MonthlyCharges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Dependents'].isnull(), 'Dependents'] = train_df.loc[train_df['Dependents'].isnull(), 'MultipleLines']\n",
    "test_df.loc[test_df['Dependents'].isnull(), 'Dependents'] = test_df.loc[test_df['Dependents'].isnull(), 'MultipleLines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Dependents'] == 'No phone service', 'Dependents'] = 'No'\n",
    "test_df.loc[test_df['Dependents'] == 'No phone service', 'Dependents'] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A função setup permite muitas customizações para treinamento dos modelos\n",
    "\n",
    "A função setup permite customizar (dentre outros):\n",
    "- tratamento de missing data simples e com algoritmos\n",
    "- over e undersampling\n",
    "- principal component analysis (PCA)\n",
    "- variaveis polinomiais\n",
    "- razão entre variáveis\n",
    "- % de treino e validação\n",
    "- tratamento de colinearidade\n",
    "- normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal! Todas as configurações para treinamento dos modelos se dá no setup.\n",
    "\n",
    "clf1 = setup(train_df, target = 'Churn', session_id=123, experiment_name='teste_1', feature_ratio=True, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que compara vários modelos de uma só vez, com várias métricas\n",
    "\n",
    "One Function to rule them all, One Function to find them, One Function to bring them all, and in the darkness of jupyter notebook's theme bind them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='./img/ring.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa 15 modelos de uma vez\n",
    "best_model = compare_models(exclude=['catboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os melhores modelos de acordo com acurácia\n",
    "modelo_lr = create_model('lr')\n",
    "modelo_gbc = create_model('gbc')\n",
    "modelo_ada = create_model('ada')\n",
    "modelo_lightgbm = create_model('lightgbm')\n",
    "#modelo_catboost = create_model('catboost')\n",
    "modelo_ridge = create_model('ridge')\n",
    "modelo_lda = create_model('lda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tunar os hiperparametros (pode demorar mais, pode tentar só com o create_model)\n",
    "tuned_lr = tune_model(modelo_lr)\n",
    "tuned_gbc = tune_model(modelo_gbc)\n",
    "tuned_ada = tune_model(modelo_ada)\n",
    "tuned_lightgbm = tune_model(modelo_lightgbm)\n",
    "#tuned_catboost = tune_model(modelo_catboost)\n",
    "tuned_ridge = tune_model(modelo_ridge)\n",
    "tuned_lda = tune_model(modelo_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finaliza os modelos, ou seja, com os melhores hiperparametros, treinar na base de treino completa\n",
    "f_lr = finalize_model(tuned_lr)\n",
    "f_gbc = finalize_model(tuned_gbc)\n",
    "f_ada = finalize_model(tuned_ada)\n",
    "f_lightgbm = finalize_model(tuned_lightgbm)\n",
    "#f_catboost = finalize_model(tuned_catboost)\n",
    "f_ridge = finalize_model(tuned_ridge)\n",
    "f_lda = finalize_model(tuned_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de ensembles\n",
    "\n",
    "Combinação de modelos pode ser útil para melhoria e generalização do modelo. O PyCaret permite ensemble com blending e stacking. Blending é uma espécie de votação e stacking utiliza as predições de um modelo para servir de variáveis explanatórias para o próximo. Uma grande vantagem de ensembles é que pode tornar o modelo mais robusto, com predições de diferentes tipos de algoritmos. Sugere-se utilizar algoritmos com abordagens bem diferentes (ex: redes neurais, algoritmos de árvore e algoritmos lineares).\n",
    "\n",
    "No exemplo vamos utilizar um blending com votação \"hard\", ou seja, utiliza cada predição como 0 ou 1 na votação. O método \"soft\" utiliza as probabilidades de saída de cada modelo, o que pode melhorar o tuning do modelo final.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votacao com os 6 modelos\n",
    "blender_hard = blend_models(estimator_list = [f_lightgbm,\n",
    "                                                f_ada,\n",
    "                                                f_lr,\n",
    "                                                f_gbc,\n",
    "                                              f_ridge,\n",
    "                                              f_lda,\n",
    "                                              # f_catboost\n",
    "                                             #   tuned_gbc,\n",
    "                                             #   tuned_catboost\n",
    "                                             ], method = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrando a matriz de confusao\n",
    "plot_model(blender_hard, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finaliza o modelo: treina com a base de treino inteira\n",
    "f_blender_hard = finalize_model(blender_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realiza as predições (duas colunas: score e label)\n",
    "predictions = predict_model(f_blender_hard, data = test_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca os labels (0 e 1). \n",
    "# Pode-se fazer alguma analise do melhor ponto de corte do Score, pois o label pega 0,5 pra cima como 1\n",
    "pred_values = predictions['Label']\n",
    "pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_df.index\n",
    "output = pd.DataFrame({'id': ids, 'Churn': pred_values})\n",
    "output.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
